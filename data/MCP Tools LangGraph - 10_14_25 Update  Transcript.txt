MCP Tools LangGraph - 10/14/25 Update 
Tue, Oct 14, 2025

0:00 - Matthew Prisco
for Ali, we're going to recap some of the preliminary discussion, and then hopefully Ali will join by the time we get to the group part. So I was just discussing for the Slack bot, we've set up Slack permissions, and now we need to decide how the bot's going to be triggered by a Slack a message or by a team member via Slack. It sounds like the bot would need to be called by the at symbol rather than a hashtag. I wonder if both are options because I could make a case that other automations would need a hashtag, but at is fine as well. It doesn't really matter. But my additional idea would be if on certain channels, if the bot is on all the time, then every message would be sent to Langraff to the early part of the QA node or of the QA workflow just to decide based on this message and maybe the other messages for the day, should I create a response even if I wasn't tagged by the user? So this would be a lot more interaction between the Slack API and the listener. So it would be triggering at every message so that it wouldn't be as important for the user to remember to tag the bot. And then the bot would just be saying based on this message and maybe based on the context of the previous messages should I give an answer and that may be as easy as yeah that sounds aligned and it's if it detects missing alignment or something that it would need to clarify that it can just post its message but still using the rest of the process would be the same, just an extra node or an extra chain or whatever it is for determining based on a message that was not requesting a response from the user, it can decide, should it respond anyway? I just did a quick search, Matthew, and it says that it's possible, but that Slack has tightened its rate limits. So we might have to batch.

2:56 - Unidentified Speaker
Can I add into this?

3:00 - Matthew Prisco
So basically, the idea is good, but there will be a lot of resource consumptions, like we will be triggering the L them again and again and there will be a lot of token consumption if we are going to use some paid model let's say open yeah yeah I would say it should be a free model or a very inexpensive model all it's being asked is you know if this is a message that just says okay good obviously there's no reason that it should respond but if it's a you know the more the more the more content in the message the more likely the bot should answer and in general I think we'll need to evaluate what LLM model choices. Okay here's Ali.

3:54 - Jawad Khan
Yeah that's right if we use some inefficient model like mostly free free time models are not that efficient so there will be Hallucination in tool calling and that can cause some trouble but if we use some of the cheaper model if we have some cheaper choice that will also work, so What I want to propose is that you can despite like instead of triggering the LLM on another channel again and again we can actually create a cache or some source of our temporary storage where for example if we are counting thousand messages per day and in a time span of eight to nine hours we can divide into like in some brackets or matrices like let's say two hours and we can we can actually bunch them together and in that message of time like hours next to hours we can actually trigger that LLM to contemplate on the messages, whether he or it should be added or not.

5:04 - Matthew Prisco
Part of the, the utility is the, the speed of getting the response so that they can keep working in stride or make a small correction that saves time from something that they weren't thinking about. Um, so I do think it would be important, uh, to, you know, to have the decision making really to be every message rather than batching, or certainly not a batch of hours at a time, maybe, you know, five or 10 minutes might be reasonable. But I also think that the, so this isn't saying that the whole workflow would use the free LLM, it would be only the part of should I respond is the lower tier LLM. And then I would expect that we want most of the LLM chains or the LLM prompts to use better models inside of the decision-making and the prompting, the answer drafting, but just for the part of should it, trigger the bot, I think that, I'm not even worried about hallucination. There's no problem if it gives an answer to something that it wasn't that important, no big deal. We just got an extra answer. Does that make sense? All right, now I'll just, I don't know, what was that?

6:48 - Hamna Rafi
Jawa's concern is very valid, but I, because we will be making LLM calls again and again. There is a thing, event-based triggers, basically, instead of a user typing a command, the board can be set to run a specific event occurred within the Slack. So I think we can use it.

7:14 - Matthew Prisco
The message received, I assume, is a trigger. So that's the easy way that this would work of just how would we have it route somewhat differently? It may not even need to, but maybe just the logic of if the bot was triggered automatic, we need a response. And if it wasn't then run the, should I respond? All right, let me update Ali real quick, and then we can kind of start the group portion. So, we were just talking about how the Slack users can trigger the knowledge bot, and now we're thinking that it could also evaluate should it respond even if it wasn't triggered. And that that would, I guess the part of this that overlaps with the main MCP tools is really the workflow for the Slack bot is going to use the central decision making and context of Ali's workflow. And then retrieving the context and what LLM models will we need there, I think are going to be, there's more value to using better models than on the front end of deciding should the bot respond or not. Ali, does that make sense?

9:12 - Unidentified Speaker
Mohamed, who are you?

9:15 - Matthew Prisco
What was that?

9:18 - Unidentified Speaker
Can you hear me?

9:19 - Ali Tallat
I heard you, but I didn't understand.

9:21 - Matthew Prisco
Oh, all right. Yeah, so yeah, it makes sense to me. What are the next steps for all of us?

9:30 - Matthew Prisco
OK, but we were just discussing Um, the next step is, um, I had over, I guess the end of last week, I took the draft from the air table, uh, nodes and edges and conditions and chains and tools. And, um, Jawad was, uh, nice enough to draft. Some code style guidelines so that really the idea would be let's draft just a high level or first draft of everyone's code and see how well did it do if based on sort of the vision that each of you would have had for your the code for your workflows how close Did the draft in the air table metadata plus the code guidelines, how close did that get to what you would have done on your own or what you had in mind? And then what are the parts that it wasn't able to fill in? So maybe there are just things that we haven't given it context for how to create that chain. Or that tool so what are the parts that we're missing and then what I'd like to discuss on the call is how can we standardize the config side so if we didn't have air table and we didn't have the meta documentation if we didn't have the IO formats in the field mappings and the rule sets that in an 8n we've been using I know with with lang graph or with lang chain or any code the best practice would be or the normal practice would be to have a config file and what I'm thinking is that we can still leverage the all of the tables that are in Airtable as the configs but that we could have a structure and really an automation that can create and update all of the config files. So, whereas N8n is dynamically fetching the configs, we could, you know, get more into that if we need to, but I'm assuming that you guys would, for latency reasons, would prefer not to have the lang chain fetching configs over and over and over again. But really what would matter is just having the config file match what it would have pulled anyway. And then I think Afolabi would be able to help us with an N8n automation that can create the config files in a standard format, and that if we make changes to the configs, that it can update the config file. So that's the main thing that I wanted to talk about since I imagine that the drafts of the workflows haven't taken that into account. So that's what I wanted to mention. Anybody have a comment on that? Just based on what I shared so far? Don't be shy. Jawad says thumbs up. Makes sense. So then I'll ask more specifically. So how were you I know this was just the draft of the code from the LLM. How was it handling the configs or was it? And then is that kind of, maybe we can discuss if it's pulling data from, I guess some of it, it needs to come from the node or the chain. I think there's that category of config of land graph configs. Then there's sort of our core data strategy infrastructure of the IO formats and the field mappings and the rule sets. So I'm not sure what combination of those tables would need to be in the config file. Does anybody have any idea?

14:38 - Hamna Rafi
Right now, my mock implementation is basically, it is using a mock implementation for both configs and data.

14:49 - Unidentified Speaker
Say that again?

14:52 - Hamna Rafi
A mock implementation. For both configs and data, yeah. Because it was just a drop.

15:00 - Matthew Prisco
So to match the MCP tools pattern, the config loader so it will Read all the configuration from the lg node table in the air table and connect the connect to the air table api to fetch the like pcf data okay so where I think this could come into play is also with cool templates and tools and then tools linking to chains so if If we have a, you know, the standard air table retrieval, air table writer, the rag writer, rag retriever, all of those kinds, those seem like candidates for tool templates, and then can we, you know, use this approach the one tool template can be, we'll have to see, in order to use what we have with IO formats and field mappings to make that version or that tool rather than the tool template. So to make that tool work, would it need to fetch it dynamically or could that be in the config And do we have too many configs to make that it would make a very messy config file? Or, you know, we'll have to see what that looks like, but definitely this would apply also to tool templates. And can each of you, you know, after the call, look closer at what are the tools that are needed and are those tool templates so that we can create those templates once and then in the configs link them to create the tools that are used by individual nodes. So I've got it conceptually, I just don't know what that, whether there's any challenges with doing that with the code. Anybody think? I'm probably oversimplifying it, but I also think it's possible.

17:34 - Jawad Khan
I just confused where you said like we will create a tool template and then we will like be loading the configs again and again. For like in technical like in technical terms configuration that I consider would be referred to the state of the of the agent state of the all the link chain workflow. Is that make sense? Are the configs related to that like the like we can make it multi-state workflow or multi-state agents. We can dynamically load the configuration that will actually hold different parameters for the workflow, different kind of like, I just forgot the configuration that you shared in the PDF. There were some PCF states as I try and component. Is that something similar to my understanding?

18:40 - Matthew Prisco
I think when you're mentioning state management, to me that sounds more like memory rather than config. Obviously, managing the state is important with anything with LandGraph, but I think those are two separate parts about what would be in a config file as opposed to managing the runtime and the states of the runtime. Am I wrong? I don't have a lot of experience with this but that's that's my understanding of of where memory fits in and state.

19:23 - Jawad Khan
Can Dwayne help us in that like how we can understand the configuration or conflict?

19:32 - Matthew Prisco
I think that's going to be Afolabi's part of looking I think in N8n where if we have workflows, existing ones, that might be candidates for lang chain, or that lang graph will need to call these N8n workflows, that when N8n fetches an IO format, then it looks for linked field mappings, then it looks for linked rule sets, it must be assembling that, I assume in JSON, and then using it with the rest of the workflow. I think that that assembled JSON could be part of the config file, and that we could have an automation so that if we make changes to what's in Airtable, change a rule set, change a field mapping, we would just update the config file. So none of that is runtime or state oriented. It's just for managing the declarative if I'm using the right terminology.

21:08 - Jawad Khan
So, it's more like the part of N8n workflow. How it is linked with all three workflows at this time period?

21:17 - Matthew Prisco
Well, the part that we need to figure out is how could LandGraph use use IO formats and field mappings and rule sets. So it needs the rules from it, even if we don't want to fetch dynamically the way that N8n has been doing it. And my compromise of how would we use the configs, and Airtable is the source of truth for versioning purposes, have an easy way to create a format that can be digested by the Langraff side, it seems like that would be the choice of do we make a config file and have Langraff use the config file, would reduce latency, would be a more traditional way to set it up, but then we would work on an automation probably using N8n to create the formatted versions of the config files.

22:30 - Jawad Khan
Okay, now what I got is like, N8n have the workflow where whenever something changes at the Airtable, the whole workflow triggers and update the config.json. Okay, so for our work, what Langroth workflows will do for any case, for any case like when we are dealing with input output or some field mapping, we have to acquire the knowledge or we have to fetch that config.json from the workflow instead of just hitting the Airtable API. So we just have to fetch from the Airtable workflow.

23:11 - Matthew Prisco
No, I think parts of that you were on the right track. One option would be do like N8N and the tool template would say, here's how an Airtable reader works. Here's how an Airtable writer works, but bring the IO format and the field mappings and the rule sets in order to fetch the right fields for that use of the tool. So this gives us a way to connect tool templates to tools. But rather than fetching directly from Airtable, I think for latency and for scalability, it would be better to have those as in a config file. And that we could have the automation that if we make changes to a config. Usually, we're not going to be making changes to these. Right now, we're building everything, trying to figure out what will work, but it would get to a state where we would only change the configs for the PCF parser and N8N Imaginator and all of the tools. We would very rarely change those configs. And if we make a change to the config in Airtable, we would rerun the automation so that those can be reflected in the config file. So really, we would just need to start working from the idea that there will be a config file either for each of these three sub-workflows or one master config file, whatever makes sense. So that's why I was wondering which of the three workflows already has a config file that was proposed by the current draft and if not then we should ask about that in the next iteration of drafting the code.

25:32 - Jawad Khan
So basically the config will provide the tool templates like the parameter structures for all the tools that we have We know our workflows.

25:40 - Matthew Prisco
So a tool template plus an IO format and a prompt. I think that's typically what makes a tool different from a tool template.

25:51 - Jawad Khan
Yeah, exactly. So, but in LangChain, like it's a convention, what we do actually, LangChain have this format. We actually provide a docstring. A docstring is like something, information or documentation about a tool. So, we have to write a docstring in that tool function declaration. So, whenever an LLM is binded with those tools, it can like the framework is designed in such a way that LLM can actually get that docstring. Like for example, we can take a very basic example where we have some additional tool where we have subtraction tool. Whenever you prompt the agent to like 2 plus 2. So it will use the docstring of those tools like if we have addition tool then there will be some docstring like this tool is for addition purpose and it takes parameter a, b and return an integer etc. Same for the subtraction maybe it will say it actually subtract. So we actually hard code like we can we provide inside that function declaration. So for that purpose, if we are using LinkedIn, then I think we don't need the configuration JSON, because it will be already declared inside the tools.

27:17 - Matthew Prisco
For some tools, that makes sense, subtraction. But I think for the IO formats and the field mappings, there's so much to it that the whole point is to use what's in Airtable. Rather than coding it into the chain or into the tool level, and then having to go in and make changes to the tool level and all of that code. What I've been trying to optimize for is kind of the modularity and the config-driven nature of the system. So I'm not saying that there aren't best practices and that there's not a way to do it with putting it in the code. I'm trying to say is there a way that we could put it in a config file and then we would just need to work out how do we create those config files.

28:24 - Jawad Khan
But somehow we have to code that like tool description inside the tools. Otherwise the link chain tool declaration will not work. So we have to search on that like I need to search on that whether it will be feasible or we can do it or we can't. So first we need to check that then we can actually like give our decision that is it possible or not.

28:54 - Matthew Prisco
I think that's a good next step is kind of especially for the the nodes that or for the parts that are going to be heavily dependent on field mappings. I think the whole MCP tool idea is that running a tool we'd said it could all be on one node but maybe we want to have a few categories of nodes or does every tool get its own node. As we start to consolidate them, it would require using field mappings and prompts, ideally with some config or fetching from Airtable. So I think it'd be good for at least Ali and Jawad to follow up with this, give the transcript from the meeting, give the, um, uh, existing draft, whatever the code and, and just see what that would look like in a way that, that you guys are, uh, you know, whatever you think would be best individually and see if we can come to a consensus about how that can be done as our land graph, uh, architecture or our best practice. And then I would ask if Afolabi can do that sort of feasibility analysis, because he's the one who's most familiar with how we've been using the IO formats and field mappings and the success that we've had with that, and see how that could also be leveraged with a config file, or is that not realistic? And something like what Jawad was outlining, if that's really our only option. Does that work? Yes is from Afolabi. Jawad, does that align? Ali says yes.

31:10 - Jawad Khan
Yeah, yeah, sure.

31:14 - Matthew Prisco
Hamna, I don't think there's as much of the config stuff on your side, but...

31:20 - Hamna Rafi
Yeah, because I don't have anything for the Slack bot.

31:27 - Matthew Prisco
The Slack bot is new. At least PCF parser, we were trying to build it in N8n, but the MCP engine and the MCP tools, those were increasingly config driven. So a lot of them started as a hard-coded workflow for each tool, and then we started consolidating them. So in order to make the consolidation happen, that's where the relationships between I-O formats and field mappings and rule sets and then where it's pulling from the data dictionary where that became important to make the system dynamic. I know that comes with trade-offs on latency, and now the exercise is to evaluate how can we use some elements from that, and maybe the answer is in the config file, or maybe it's just use what's in Airtable to hard code all of the workflows if the config file is not a good idea for some reason. But it'd be good if we can have at least everybody sort of try to see, could this work with configs even if that's not the norm? And then that's going to be, I think, a less biased opinion I at least want everybody to evaluate that and see if you really don't like it, we don't need to do that. But I think it's important that we give it a fair shot to try, um, to have a real config driven system. Ali, do you have anything to add on that? Just cause I think yours is probably the most important about how much we're using for configs would also dictate what nodes we need.

33:44 - Ali Tallat
Yeah, I agree with you on that, Matthew. And no, I don't have anything from IAM at the moment, but if I do, I'll make sure to follow up with you.

33:55 - Matthew Prisco
All right. So then I think in terms of priorities for off the call, anybody can comment on the config stuff. It'll be really important for that to come from Ali. I know Afolabi will give his take on it. I think for Jawad, one of the important follow-up points is really RAG and knowledge graphs because I think PCF parser is the first one to touch those. So I think he's been the one who's looked at graffiti for the knowledge graph. And has been into SuperBase and that populating the RAG database and the knowledge graphs is going to require running the PCF parser. Whether that is done locally or we get this running, we're going to have dozens of meetings recordings between me and Dwayne that we're going to need to process before the knowledge bot is going to be able to give good answers. So I think that's going to require probably, you know, a lot of his attention. And I assume that's why he nominated himself for the PCF parser is because of the RAG and the knowledge graph side of it. And he's a already been working on that. But I think that's going to be important for moving this forward, is not just getting the workflow drafted, but once that's ready, once we're able to have success with using the PCF table to match and create the PCF parser summaries, those are getting then processed to RAG, processed to the Knowledge Graph, and processed I'm starting to think that the PCF context document, it would be good to have it create bullet points for that, rather than just sheer unstructured instructions and context. We've been working with Clyde, who I also added to the channel, has been creating some PCF context documents as PDFs or Google manually so that we can see what one might look like so we can find a prompt that we can use in the PCF parser to create those and update them. So again, that's another thing for Jawad. Kind of like Hamna, I don't think there's as much of the config driven other than PCF which it doesn't really matter too much whether that's hard-coded or config.

36:58 - Hamna Rafi
So, I think, what was that, Amna?

37:02 - Hamna Rafi
Oh, I was with you.

37:05 - Matthew Prisco
Okay, good. So, yes, feedback about the config-driven system. It really, I think, is going to be heavily on And then the group can sort of work through if there are any suggestions about what could make that scalable. But I think for Jawad, it's if he wants to go ahead and code some version of the PCF parser, so to run it locally. And then how do we go to the PCF table and create a subgraph? We can have a graph for the whole MCP tool and PCF ecosystem, and that we would need to have an automation to create a subgraph for each of the current or active PCFs. So, for right now, I think the first ones would be created manually, create a subgraph, for each of your workflows are features. So, FLAC, Q&A, PCF parser, and MCP tool brain or whatever we're going to call those, those are each PCFs. And the knowledge or the instructions as we're processing these meetings, like this one, that we need to think about how How will the PCF parser take this meeting and find what was relevant to each of the three workflows and put that on its knowledge graph or the knowledge graph for each of those? But there would also be a knowledge graph for the component. So what is the level above each of the sub-workflows or each of the features? What is the component and how do we manage that knowledge graph? And if the project is MCP tools, how can we take this meeting and get the relevant parts onto all of those, I assume, separate subgraphs? So that's, I don't think there's only one way to do that. I think there are some decisions that we could make. And then where, in particular, Dwayne will need to help us is on what is our PCF hierarchy? The project here is MCP Tools. What is the component that connects all of these features? What other components are out there that are part of MCP Tools? And what are we going to name those officially? And I think we will have an automation, I was talking with Jawad about this, that can evaluate the current PCF table and help us organize these more logically if it notices that there's no component. And do we need to make that a rule that you can only have a full hierarchy? If there are features at least one component that they're linked to, or they need to be linked to a component, and each component needs to be linked to a project. Does that work as a rule? And that we can have an LLM and a chain that can help us better organize. Once we have organization that we're happy with, then we create the knowledge graphs for each of those. Then we can run the PCI to get the backlog of meetings onto those graphs. And then we can also process the backlog of Slack messages to put the knowledge on the right PCF. And then moving forward, if we have a meeting and we mentioned a PCF or what will need to be a PCF for the first time, that chain can notify us, hey, we think there's be a new PCF, here's what we suggest. Or another possibility is merging two existing PCFs or splitting an existing PCF into two or other types of changes that for as long as we've been sort of moving toward the PCF structure, maybe we've created 250 and we need to now organized what we have and I think that that chain would be important for making sure that our structure becomes optimized. We'll need a name for this. I was thinking something about taxonomy or or PCF taxonomizer or something like that. Does that need its own node or is that Is that a tool? That's where I kind of struggle with, do we have decisions about those kind of things? That'd be a question, I guess, for Ali on, on the, is this a, well, part of it feels like it relates to Ali's part, but obviously it definitely relates to on JWADs as well. Does that make sense, guys?

42:58 - Jawad Khan
Yes, and I am actually working on the RAD and Neo4j setup. So for Neo4j, I got some options, like we have three options. Directly deploy on the virtual machine that we already have on DigitalOcean, like creating some Docker image and running it on that. And the second option is like we will use the Kubernetes of the digital ocean. And the third option is directly using the Neo4j or RDB that that is cloud hosted and provided by them.

43:32 - Jawad Khan
So I will use those three.

43:41 - Jawad Khan
Yes, but I will search on which one is efficient and which one is like cost-efficient for us and then we will choose the best one.

43:51 - Matthew Prisco
Do you like graffiti? I think that's really the first question is do we use graffiti plus one of those three Neo4j options or do we use that which is all?

44:01 - Jawad Khan
Yeah actually graffiti is the framework that is actually used to extract the entities from the upcoming data and they are called as episodes. So from each episode is some information, let's say some messages, one of the message from the Slack messages, and all the graffiti will extract some entity relationship from each other, like matching the stories and connecting the graph and giving them weight. So graffiti has to deal with it, but Neo4j, Neo4j is actually a storage database that actually stored that graph structure. So the Neo4j actually have three options, Kubernetes, DigitalOcean virtual machine, and Neo4j or RDB hosted, that is a service provided by them. So I will search on all of three of them and for like testing purposes, I will use the local variant like Neo4j Neo4j on my local device, but as the DB is going to be used by all of these three workflows, so we have to actually choose the better option, like the most efficient one, that actually I think the Neo4j or RDB version is.

45:32 - Jawad Khan
So I will actually provide a draft in the group, so everyone can comment on that, and then we will Well, we have Superbase, so we're not trying to self-host Superbase, so it'd be kind of the same decision about...

45:48 - Jawad Khan
Yeah, that's the same. We will use the same Superbase.

45:54 - Matthew Prisco
Yeah, I'm open to using Neo4j Cloud, if that makes this easier for now. I would hope that we could port that later if need be, or if that would be what an enterprise would do. Um, we would just need to think about a few steps ahead as well, but primarily what makes sense for now. Um, okay. So I think, I think that should give everybody a few things to follow up with. And, um, just today, Monday or Tuesday, today's Tuesday. So got a couple of days this week, hopefully to, um, to get closer to being able to run one or more of these and start to see it in action. And we'll distribute the transcript probably for tomorrow. I'll try to use that to summarize some things. But we'll take it back to Slack. Anything to add? All right. All right. Let's go do it. Good luck.

47:11 - Unidentified Speaker
Thank you.